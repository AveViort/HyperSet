<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Gaussian processes for regression and classification</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for gausspr {kernlab}"><tr><td>gausspr {kernlab}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2> Gaussian processes for regression and classification</h2>

<h3>Description</h3>

<p><code>gausspr</code> is an implementation of Gaussian processes
for classification and regression.
</p>


<h3>Usage</h3>

<pre>


## S4 method for signature 'formula'
gausspr(x, data=NULL, ..., subset, na.action = na.omit, scaled = TRUE)

## S4 method for signature 'vector'
gausspr(x,...)

## S4 method for signature 'matrix'
gausspr(x, y, scaled = TRUE, type= NULL, kernel="rbfdot",
          kpar="automatic", var=1, variance.model = FALSE, tol=0.0005,
          cross=0, fit=TRUE, ... , subset, na.action = na.omit)


</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x</code></td>
<td>
<p>a symbolic description of the model to be fit or a matrix or
vector when a formula interface is not used. 
When not using a formula x is a matrix or vector containing the variables in the model</p>
</td></tr> 
<tr valign="top"><td><code>data</code></td>
<td>
<p>an optional data frame containing the variables in the model.
By default the variables are taken from the environment which
&lsquo;gausspr&rsquo; is called from.</p>
</td></tr>
<tr valign="top"><td><code>y</code></td>
<td>
<p>a response vector with one label for each row/component of <code>x</code>. Can be either
a factor (for classification tasks) or a numeric vector (for
regression).</p>
</td></tr>
<tr valign="top"><td><code>type</code></td>
<td>
<p>Type of problem. Either &quot;classification&quot; or &quot;regression&quot;.
Depending on whether <code>y</code> is a factor or not, the default
setting for <code>type</code> is <code>classification</code> or <code>regression</code>,
respectively, but can be overwritten by setting an explicit value.<br /></p>
</td></tr>
<tr valign="top"><td><code>scaled</code></td>
<td>
<p>A logical vector indicating the variables to be
scaled. If <code>scaled</code> is of length 1, the value is recycled as
many times as needed and all non-binary variables are scaled.
Per default, data are scaled internally (both <code>x</code> and <code>y</code>
variables) to zero mean and unit variance. The center and scale
values are returned and used for later predictions.</p>
</td></tr>
<tr valign="top"><td><code>kernel</code></td>
<td>
<p>the kernel function used in training and predicting.
This parameter can be set to any function, of class kernel, which computes a dot product between two
vector arguments. kernlab provides the most popular kernel functions
which can be used by setting the kernel parameter to the following
strings:
</p>

<ul>
<li> <p><code>rbfdot</code> Radial Basis kernel function &quot;Gaussian&quot;
</p>
</li>
<li> <p><code>polydot</code> Polynomial kernel function
</p>
</li>
<li> <p><code>vanilladot</code> Linear kernel function
</p>
</li>
<li> <p><code>tanhdot</code> Hyperbolic tangent kernel function
</p>
</li>
<li> <p><code>laplacedot</code> Laplacian kernel function
</p>
</li>
<li> <p><code>besseldot</code> Bessel kernel function
</p>
</li>
<li> <p><code>anovadot</code> ANOVA RBF kernel function
</p>
</li>
<li> <p><code>splinedot</code> Spline kernel 
</p>
</li></ul>

<p>The kernel parameter can also be set to a user defined function of
class kernel by passing the function name as an argument.
</p>
</td></tr>
<tr valign="top"><td><code>kpar</code></td>
<td>
<p>the list of hyper-parameters (kernel parameters).
This is a list which contains the parameters to be used with the
kernel function. Valid parameters for existing kernels are :
</p>

<ul>
<li> <p><code>sigma</code> inverse kernel width for the Radial Basis
kernel function &quot;rbfdot&quot; and the Laplacian kernel &quot;laplacedot&quot;.
</p>
</li>
<li> <p><code>degree, scale, offset</code> for the Polynomial kernel &quot;polydot&quot;
</p>
</li>
<li> <p><code>scale, offset</code> for the Hyperbolic tangent kernel
function &quot;tanhdot&quot;
</p>
</li>
<li> <p><code>sigma, order, degree</code> for the Bessel kernel &quot;besseldot&quot;. 
</p>
</li>
<li> <p><code>sigma, degree</code> for the ANOVA kernel &quot;anovadot&quot;.
</p>
</li></ul>

<p>Hyper-parameters for user defined kernels can be passed through the
kpar parameter as well.</p>
</td></tr>
<tr valign="top"><td><code>var</code></td>
<td>
<p>the initial noise variance, (only for regression) (default
: 0.001)</p>
</td></tr>
<tr valign="top"><td><code>variance.model</code></td>
<td>
<p>build model for variance or standard deviation estimation (only for regression) (default
: FALSE)</p>
</td></tr>
<tr valign="top"><td><code>tol</code></td>
<td>
<p>tolerance of termination criterion (default: 0.001)</p>
</td></tr>
<tr valign="top"><td><code>fit</code></td>
<td>
<p>indicates whether the fitted values should be computed and
included in the model or not (default: 'TRUE')</p>
</td></tr>
<tr valign="top"><td><code>cross</code></td>
<td>
<p>if a integer value k&gt;0 is specified, a k-fold cross
validation on the training data is performed to assess the
quality of the model: the Mean Squared Error for regression</p>
</td></tr>
<tr valign="top"><td><code>subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the
training sample.  (NOTE: If given, this argument must be
named.)</p>
</td></tr>
<tr valign="top"><td><code>na.action</code></td>
<td>
<p>A function to specify the action to be taken if <code>NA</code>s are
found. The default action is <code>na.omit</code>, which leads to
rejection of cases with missing values on any required variable. An
alternative is <code>na.fail</code>, which causes an error if <code>NA</code>
cases are found. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p> additional parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Gaussian process is specified by a mean and a covariance function.
The mean is a function of <i>x</i> (which is often the zero function), and
the covariance
is a function <i>C(x,x')</i> which expresses the expected covariance between the
value of the function <i>y</i> at the points <i>x</i> and <i>x'</i>.
The actual function <i>y(x)</i> in any data modeling problem is assumed to be
a single sample from this Gaussian distribution.
Laplace approximation is used for the parameter estimation in gaussian
processes for classification.<br />
</p>
<p>The predict function can return class probabilities for 
classification problems by setting the <code>type</code> parameter to &quot;probabilities&quot;.
For the regression setting the <code>type</code> parameter to &quot;variance&quot; or &quot;sdeviation&quot; returns the estimated variance or standard deviation at each predicted point.
</p>


<h3>Value</h3>

<p>An S4 object of class &quot;gausspr&quot; containing the fitted model along with
information.
Accessor functions can be used to access the slots of the
object which include :
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>alpha</code></td>
<td>
<p>The resulting model parameters</p>
</td></tr>
<tr valign="top"><td><code>error</code></td>
<td>
<p>Training error (if fit == TRUE)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexandros Karatzoglou <br /> <a href="mailto:alexandros.karatzoglou@ci.tuwien.ac.at">alexandros.karatzoglou@ci.tuwien.ac.at</a></p>


<h3>References</h3>

<p>C. K. I. Williams and D. Barber <br />
Bayesian classification with Gaussian processes. <br />
IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(12):1342-1351, 1998<br />
<a href="http://www.dai.ed.ac.uk/homes/ckiw/postscript/pami_final.ps.gz">http://www.dai.ed.ac.uk/homes/ckiw/postscript/pami_final.ps.gz</a>
</p>


<h3>See Also</h3>

<p><code><a href="predict.gausspr.html">predict.gausspr</a></code>, <code><a href="rvm.html">rvm</a></code>, <code><a href="ksvm.html">ksvm</a></code>, <code><a href="gausspr-class.html">gausspr-class</a></code>, <code><a href="lssvm.html">lssvm</a></code> </p>


<h3>Examples</h3>

<pre>
# train model
data(iris)
test &lt;- gausspr(Species~.,data=iris,var=2)
test
alpha(test)

# predict on the training set
predict(test,iris[,-5])
# class probabilities 
predict(test, iris[,-5], type="probabilities")

# create regression data
x &lt;- seq(-20,20,0.1)
y &lt;- sin(x)/x + rnorm(401,sd=0.03)

# regression with gaussian processes
foo &lt;- gausspr(x, y)
foo

# predict and plot
ytest &lt;- predict(foo, x)
plot(x, y, type ="l")
lines(x, ytest, col="red")


#predict and variance
x = c(-4, -3, -2, -1,  0, 0.5, 1, 2)
y = c(-2,  0,  -0.5,1,  2, 1, 0, -1)
plot(x,y)
foo2 &lt;- gausspr(x, y, variance.model = TRUE)
xtest &lt;- seq(-4,2,0.2)
lines(xtest, predict(foo2, xtest))
lines(xtest,
      predict(foo2, xtest)+2*predict(foo2,xtest, type="sdeviation"),
      col="red")
lines(xtest,
      predict(foo2, xtest)-2*predict(foo2,xtest, type="sdeviation"),
      col="red")

</pre>

<hr /><div style="text-align: center;">[Package <em>kernlab</em> version 0.9-27 <a href="00Index.html">Index</a>]</div>
</body></html>
