<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Least Squares Support Vector Machine</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for lssvm {kernlab}"><tr><td>lssvm {kernlab}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Least Squares Support Vector Machine</h2>

<h3>Description</h3>

<p>The <code>lssvm</code> function is an
implementation of the Least Squares SVM. <code>lssvm</code> includes a
reduced version of Least Squares SVM using a decomposition of the
kernel matrix which is calculated by the <code>csi</code> function.
</p>


<h3>Usage</h3>

<pre>

## S4 method for signature 'formula'
lssvm(x, data=NULL, ..., subset, na.action = na.omit, scaled = TRUE)

## S4 method for signature 'vector'
lssvm(x, ...)

## S4 method for signature 'matrix'
lssvm(x, y, scaled = TRUE, kernel = "rbfdot", kpar = "automatic",
      type = NULL, tau = 0.01, reduced = TRUE, tol = 0.0001,
      rank = floor(dim(x)[1]/3), delta = 40, cross = 0, fit = TRUE,
      ..., subset, na.action = na.omit)

## S4 method for signature 'kernelMatrix'
lssvm(x, y, type = NULL, tau = 0.01,
      tol = 0.0001, rank = floor(dim(x)[1]/3), delta = 40, cross = 0,
      fit = TRUE, ...)

## S4 method for signature 'list'
lssvm(x, y, scaled = TRUE,
      kernel = "stringdot", kpar = list(length=4, lambda = 0.5),
      type = NULL, tau = 0.01, reduced = TRUE, tol = 0.0001,
      rank = floor(dim(x)[1]/3), delta = 40, cross = 0, fit = TRUE,
      ..., subset)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x</code></td>
<td>
<p>a symbolic description of the model to be fit, a matrix or
vector containing the training data when a formula interface is not
used or a <code>kernelMatrix</code> or a list of character vectors.</p>
</td></tr>
<tr valign="top"><td><code>data</code></td>
<td>
<p>an optional data frame containing the variables in the model.
By default the variables are taken from the environment which
&lsquo;lssvm&rsquo; is called from.</p>
</td></tr>
<tr valign="top"><td><code>y</code></td>
<td>
<p>a response vector with one label for each row/component of <code>x</code>. Can be either
a factor (for classification tasks) or a numeric vector (for
classification or regression - currently nor supported -).</p>
</td></tr>
<tr valign="top"><td><code>scaled</code></td>
<td>
<p>A logical vector indicating the variables to be
scaled. If <code>scaled</code> is of length 1, the value is recycled as
many times as needed and all non-binary variables are scaled.
Per default, data are scaled internally to zero mean and unit
variance. The center and scale values are returned and used for later predictions.</p>
</td></tr>
<tr valign="top"><td><code>type</code></td>
<td>
<p>Type of problem. Either &quot;classification&quot; or &quot;regression&quot;.
Depending on whether <code>y</code> is a factor or not, the default
setting for <code>type</code> is &quot;classification&quot; or &quot;regression&quot; respectively,
but can be overwritten by setting an explicit value. (regression is
currently not supported)<br /></p>
</td></tr>
<tr valign="top"><td><code>kernel</code></td>
<td>
<p>the kernel function used in training and predicting.
This parameter can be set to any function, of class kernel, which computes a dot product between two
vector arguments. kernlab provides the most popular kernel functions
which can be used by setting the kernel parameter to the following
strings:
</p>

<ul>
<li> <p><code>rbfdot</code> Radial Basis kernel &quot;Gaussian&quot;
</p>
</li>
<li> <p><code>polydot</code> Polynomial kernel 
</p>
</li>
<li> <p><code>vanilladot</code> Linear kernel 
</p>
</li>
<li> <p><code>tanhdot</code> Hyperbolic tangent kernel 
</p>
</li>
<li> <p><code>laplacedot</code> Laplacian kernel 
</p>
</li>
<li> <p><code>besseldot</code> Bessel kernel 
</p>
</li>
<li> <p><code>anovadot</code> ANOVA RBF kernel 
</p>
</li>
<li> <p><code>splinedot</code> Spline kernel
</p>
</li>
<li> <p><code>stringdot</code> String kernel
</p>
</li></ul>

<p>Setting the kernel parameter to &quot;matrix&quot; treats <code>x</code> as a kernel
matrix calling the <code>kernelMatrix</code> interface.<br />
</p>
<p>The kernel parameter can also be set to a user defined function of
class kernel by passing the function name as an argument.
</p>
</td></tr>
<tr valign="top"><td><code>kpar</code></td>
<td>

<p>the list of hyper-parameters (kernel parameters).
This is a list which contains the parameters to be used with the
kernel function. For valid parameters for existing kernels are :
</p>

<ul>
<li> <p><code>sigma</code> inverse kernel width for the Radial Basis
kernel function &quot;rbfdot&quot; and the Laplacian kernel &quot;laplacedot&quot;.
</p>
</li>
<li> <p><code>degree, scale, offset</code> for the Polynomial kernel &quot;polydot&quot;
</p>
</li>
<li> <p><code>scale, offset</code> for the Hyperbolic tangent kernel
function &quot;tanhdot&quot;
</p>
</li>
<li> <p><code>sigma, order, degree</code> for the Bessel kernel &quot;besseldot&quot;. 
</p>
</li>
<li> <p><code>sigma, degree</code> for the ANOVA kernel &quot;anovadot&quot;.
</p>
</li>
<li> <p><code>length, lambda, normalized</code> for the &quot;stringdot&quot; kernel
where length is the length of the strings considered, lambda the
decay factor and normalized a logical parameter determining if the
kernel evaluations should be normalized.
</p>
</li></ul>

<p>Hyper-parameters for user defined kernels can be passed through the
kpar parameter as well.<br />
</p>
<p><code>kpar</code> can also be set to the string &quot;automatic&quot; which uses the heuristics in 
<code><a href="sigest.html">sigest</a></code> to calculate a good <code>sigma</code> value for the
Gaussian RBF or Laplace kernel, from the data. (default = &quot;automatic&quot;).
</p>
</td></tr>
<tr valign="top"><td><code>tau</code></td>
<td>
<p>the regularization parameter (default 0.01) </p>
</td></tr>
<tr valign="top"><td><code>reduced</code></td>
<td>
<p>if set to <code>FALSE</code> the full linear problem of the
lssvm is solved, when <code>TRUE</code> a reduced method using <code>csi</code> is used.</p>
</td></tr>
<tr valign="top"><td><code>rank</code></td>
<td>
<p>the maximal rank of the decomposed kernel matrix, see
<code>csi</code></p>
</td></tr>
<tr valign="top"><td><code>delta</code></td>
<td>
<p>number of columns of cholesky performed in advance, see
<code>csi</code> (default 40)</p>
</td></tr>
<tr valign="top"><td><code>tol</code></td>
<td>
<p>tolerance of termination criterion for the <code>csi</code>
function, lower tolerance leads to more precise approximation but
may increase the training time and the decomposed matrix size (default: 0.0001)</p>
</td></tr>
<tr valign="top"><td><code>fit</code></td>
<td>
<p>indicates whether the fitted values should be computed and
included in the model or not (default: 'TRUE')</p>
</td></tr>
<tr valign="top"><td><code>cross</code></td>
<td>
<p>if a integer value k&gt;0 is specified, a k-fold cross
validation on the training data is performed to assess the
quality of the model: the Mean Squared Error for regression</p>
</td></tr>
<tr valign="top"><td><code>subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the
training sample.  (NOTE: If given, this argument must be
named.)</p>
</td></tr>
<tr valign="top"><td><code>na.action</code></td>
<td>
<p>A function to specify the action to be taken if <code>NA</code>s are
found. The default action is <code>na.omit</code>, which leads to rejection of cases
with missing values on any required variable. An alternative
is <code>na.fail</code>, which causes an error if <code>NA</code> cases
are found. (NOTE: If given, this argument must be named.)</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p> additional parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Least Squares Support Vector Machines are reformulation to the
standard SVMs that lead to solving linear KKT systems.
The algorithm is based on the minimization of a classical penalized
least-squares cost function. The current implementation approximates
the kernel matrix by an incomplete Cholesky factorization obtained by
the <code><a href="csi.html">csi</a></code> function, thus the solution is an approximation
to the exact solution of the lssvm optimization problem. The quality
of the solution depends on the approximation and can be influenced by
the &quot;rank&quot; , &quot;delta&quot;, and &quot;tol&quot; parameters.
</p>


<h3>Value</h3>

<p>An S4 object of class <code>"lssvm"</code> containing the fitted model,
Accessor functions can be used to access the slots of the object (see
examples) which include:
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>alpha</code></td>
<td>
<p>the parameters of the <code>"lssvm"</code></p>
</td></tr>
<tr valign="top"><td><code>coef</code></td>
<td>
<p>the model coefficients (identical to alpha)</p>
</td></tr>
<tr valign="top"><td><code>b</code></td>
<td>
<p>the model offset.</p>
</td></tr>
<tr valign="top"><td><code>xmatrix</code></td>
<td>
<p>the training data used by the model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexandros Karatzoglou <br /> <a href="mailto:alexandros.karatzoglou@ci.tuwien.ac.at">alexandros.karatzoglou@ci.tuwien.ac.at</a></p>


<h3>References</h3>

<p>J. A. K. Suykens and  J. Vandewalle<br />
<em>Least Squares Support Vector Machine Classifiers</em><br />
Neural Processing Letters vol. 9, issue 3, June 1999<br />
</p>


<h3>See Also</h3>

<p><code><a href="ksvm.html">ksvm</a></code>, <code><a href="gausspr.html">gausspr</a></code>, <code><a href="csi.html">csi</a></code> </p>


<h3>Examples</h3>

<pre>
## simple example
data(iris)

lir &lt;- lssvm(Species~.,data=iris)

lir

lirr &lt;- lssvm(Species~.,data= iris, reduced = FALSE)

lirr

## Using the kernelMatrix interface

iris &lt;- unique(iris)

rbf &lt;- rbfdot(0.5)

k &lt;- kernelMatrix(rbf, as.matrix(iris[,-5]))

klir &lt;- lssvm(k, iris[, 5])

klir

pre &lt;- predict(klir, k)
</pre>

<hr /><div style="text-align: center;">[Package <em>kernlab</em> version 0.9-27 <a href="00Index.html">Index</a>]</div>
</body></html>
