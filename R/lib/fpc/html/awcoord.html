<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Asymmetric weighted discriminant coordinates</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for awcoord {fpc}"><tr><td>awcoord {fpc}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Asymmetric weighted discriminant coordinates</h2>

<h3>Description</h3>

<p>Asymmetric weighted discriminant coordinates as defined
in Hennig (2003). Asymmetric discriminant projection means that there
are two classes, one of which is treated as the homogeneous class
(i.e., it should appear homogeneous and separated in the resulting projection)
while the other may be heterogeneous. 
The principle is to maximize the ratio between the projection of a between
classes separation matrix and the projection of the covariance matrix
within the homogeneous class. Points are weighted according to their
(robust) Mahalanobis distance to the homogeneous class. 
</p>


<h3>Usage</h3>

<pre>
awcoord(xd, clvecd, clnum=1, mahal="square", method="classical",
                     clweight=switch(method,classical=FALSE,TRUE),
                     alpha=0.99, subsample=0, countmode=1000, ...) 
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>xd</code></td>
<td>
<p>the data matrix; a numerical object which can be coerced
to a matrix.</p>
</td></tr>
<tr valign="top"><td><code>clvecd</code></td>
<td>
<p>integer vector of class numbers; length must equal
<code>nrow(xd)</code>.</p>
</td></tr>
<tr valign="top"><td><code>clnum</code></td>
<td>
<p>integer. Number of the homogeneous class.</p>
</td></tr>
<tr valign="top"><td><code>mahal</code></td>
<td>
<p>&quot;md&quot; or &quot;square&quot;. If &quot;md&quot;, the points are weighted by the
square root of the <code>alpha</code>-quantile of the
corresponding chi squared distribution
over the roots of their Mahalanobis distance to the
homogeneous class, unless
this is smaller than 1. If &quot;square&quot; (which is recommended), the
(originally squared) Mahalanobis distance and the
unrooted quantile is used.</p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>one of
&quot;mve&quot;, &quot;mcd&quot; or &quot;classical&quot;. Covariance matrix used within the
homogeneous class and for the computation of the Mahalanobis distances.
&quot;mcd&quot; and &quot;mve&quot; are robust covariance matrices as implemented
in <code><a href="../../MASS/html/cov.rob.html">cov.rob</a></code>. &quot;classical&quot; refers to the classical
covariance matrix.</p>
</td></tr>
<tr valign="top"><td><code>clweight</code></td>
<td>
<p>logical. If <code>FALSE</code>, only the points of the
heterogeneous class are weighted. This, together with
<code>method="classical"</code>, computes AWC as defined in Hennig (2003). If
<code>TRUE</code>, all points are weighted. This, together with
<code>method="mcd"</code>, computes ARC as defined in Hennig (2003).</p>
</td></tr>
<tr valign="top"><td><code>alpha</code></td>
<td>
<p>numeric between 0 and 1. The corresponding quantile of
the chi squared distribution is used for the downweighting
of points. Points with a smaller Mahalanobis distance to the
homogeneous class get full weight.</p>
</td></tr>
<tr valign="top"><td><code>subsample</code></td>
<td>
<p>integer. If 0, all points are used. Else, only a
subsample of <code>subsample</code> of the points is used.</p>
</td></tr>
<tr valign="top"><td><code>countmode</code></td>
<td>
<p>optional positive integer. Every <code>countmode</code>
algorithm runs <code>awcoord</code> shows a message.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>no effect</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The square root of the homogeneous classes covariance matrix
is inverted by use of
<code><a href="tdecomp.html">tdecomp</a></code>, which can be expected to give
reasonable results for singular within-class covariance matrices.
</p>


<h3>Value</h3>

<p>List with the following components
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>ev</code></td>
<td>
<p>eigenvalues in descending order.</p>
</td></tr>
<tr valign="top"><td><code>units</code></td>
<td>
<p>columns are coordinates of projection basis vectors.
New points <code>x</code> can be projected onto the projection basis vectors
by <code>x %*% units</code></p>
</td></tr>
<tr valign="top"><td><code>proj</code></td>
<td>
<p>projections of <code>xd</code> onto <code>units</code>.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Christian Hennig
<a href="mailto:c.hennig@ucl.ac.uk">c.hennig@ucl.ac.uk</a>
<a href="http://www.homepages.ucl.ac.uk/~ucakche/">http://www.homepages.ucl.ac.uk/~ucakche/</a>
</p>


<h3>References</h3>

<p>Hennig, C. (2004) Asymmetric linear dimension reduction for classification.
Journal of Computational and Graphical Statistics 13, 930-945 .
</p>
<p>Hennig, C. (2005)  A method for visual cluster validation.  In:
Weihs, C. and Gaul, W. (eds.): Classification - The Ubiquitous
Challenge. Springer, Heidelberg 2005, 153-160.
</p>


<h3>See Also</h3>

<p><code><a href="plotcluster.html">plotcluster</a></code> for straight forward discriminant plots.
<code><a href="discrproj.html">discrproj</a></code> for alternatives.
<code><a href="rFace.html">rFace</a></code> for generation of the example data used below.
</p>


<h3>Examples</h3>

<pre>
  set.seed(4634)
  face &lt;- rFace(600,dMoNo=2,dNoEy=0)
  grface &lt;- as.integer(attr(face,"grouping"))
  awcf &lt;- awcoord(face,grface==1)
  # awcf2 &lt;- ancoord(face,grface==1, method="mcd")
  plot(awcf$proj,col=1+(grface==1))
  # plot(awcf2$proj,col=1+(grface==1))
  # ...done in one step by function plotcluster.
</pre>

<hr /><div style="text-align: center;">[Package <em>fpc</em> version 2.1-11.1 <a href="00Index.html">Index</a>]</div>
</body></html>
