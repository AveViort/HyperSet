<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: DBSCAN density reachability and connectivity clustering</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for dbscan {fpc}"><tr><td>dbscan {fpc}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>DBSCAN density reachability and connectivity clustering</h2>

<h3>Description</h3>

<p>Generates a density based clustering of arbitrary shape as introduced
in Ester et al. (1996).
</p>


<h3>Usage</h3>

<pre>
  dbscan(data, eps, MinPts = 5, scale = FALSE, method = c("hybrid", "raw",
    "dist"), seeds = TRUE, showplot = FALSE, countmode = NULL)
  ## S3 method for class 'dbscan'
print(x, ...)
  ## S3 method for class 'dbscan'
plot(x, data, ...)
  ## S3 method for class 'dbscan'
predict(object, data, newdata = NULL,
predict.max=1000, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>data</code></td>
<td>
<p>data matrix, data.frame, dissimilarity matrix or
<code>dist</code>-object. Specify <code>method="dist"</code> if the data should
be interpreted as dissimilarity matrix or object. Otherwise
Euclidean distances will be used.</p>
</td></tr>
<tr valign="top"><td><code>eps</code></td>
<td>
<p> Reachability distance, see Ester et al. (1996). </p>
</td></tr>
<tr valign="top"><td><code>MinPts</code></td>
<td>
<p> Reachability minimum no. of points, see Ester et al. (1996). </p>
</td></tr>
<tr valign="top"><td><code>scale</code></td>
<td>
<p> scale the data if <code>TRUE</code>. </p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p> &quot;dist&quot; treats data as distance matrix (relatively fast
but memory expensive), &quot;raw&quot; treats data as raw data and avoids
calculating a distance matrix (saves memory but may be slow),
&quot;hybrid&quot; expects also raw data, but calculates partial distance
matrices (very fast with moderate memory requirements).</p>
</td></tr>
<tr valign="top"><td><code>seeds</code></td>
<td>
<p>FALSE to not include the <code>isseed</code>-vector in the
<code>dbscan</code>-object.</p>
</td></tr>
<tr valign="top"><td><code>showplot</code></td>
<td>
<p> 0 = no plot, 1 = plot per iteration, 2 = plot per
subiteration. </p>
</td></tr>
<tr valign="top"><td><code>countmode</code></td>
<td>
<p> NULL or vector of point numbers at which to report
progress. </p>
</td></tr>
<tr valign="top"><td><code>x</code></td>
<td>
<p>object of class <code>dbscan</code>.</p>
</td></tr>
<tr valign="top"><td><code>object</code></td>
<td>
<p>object of class <code>dbscan</code>.</p>
</td></tr>
<tr valign="top"><td><code>newdata</code></td>
<td>
<p> matrix or data.frame with raw data to predict. </p>
</td></tr>
<tr valign="top"><td><code>predict.max</code></td>
<td>
<p> max. batch size for predictions. </p>
</td></tr> 
<tr valign="top"><td><code>...</code></td>
<td>
<p>Further arguments transferred to plot methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Clusters require a minimum no of points (MinPts) within a maximum distance
(eps) around one of its members (the seed).
Any point within eps around any point which satisfies the seed condition
is a cluster member (recursively).
Some points may not belong to any clusters (noise).
</p>
<p>We have clustered a 100.000 x 2 dataset in 40 minutes on a Pentium M 1600
MHz.
</p>
<p><code>print.dbscan</code> shows a statistic of the number of points
belonging to the clusters that are seeds and border points.
</p>
<p><code>plot.dbscan</code> distinguishes between seed and border points by
plot symbol.
</p>


<h3>Value</h3>

<p><code>predict.dbscan</code> gives out a vector of predicted clusters for the
points in <code>newdata</code>.
</p>
<p><code>dbscan</code> gives out 
an object of class 'dbscan' which is a LIST with components
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>cluster</code></td>
<td>
<p>integer vector coding cluster membership with noise
observations (singletons) coded as 0 </p>
</td></tr>
<tr valign="top"><td><code>isseed</code></td>
<td>
<p>logical vector indicating whether a point is a seed (not
border, not noise)</p>
</td></tr>
<tr valign="top"><td><code>eps</code></td>
<td>
<p>parameter eps</p>
</td></tr>
<tr valign="top"><td><code>MinPts</code></td>
<td>
<p>parameter MinPts</p>
</td></tr>
</table>


<h3>Note</h3>

<p> this is a simplified version of the original algorithm (no K-D-trees
used), thus we have <i>o(n^2)</i> instead of <i>o(n*log(n))</i> </p>


<h3>Author(s)</h3>

<p>Jens Oehlschlaegel, based on a draft by Christian Hennig.</p>


<h3>References</h3>

<p> Martin Ester, Hans-Peter Kriegel, Joerg Sander, Xiaowei Xu
(1996). A Density-Based Algorithm for Discovering Clusters in Large Spatial
Databases with Noise. Institute for Computer Science, University of Munich.
Proceedings of 2nd International Conference on Knowledge Discovery and Data
Mining (KDD-96). </p>


<h3>Examples</h3>

<pre>
  set.seed(665544)
  n &lt;- 600
  x &lt;- cbind(runif(10, 0, 10)+rnorm(n, sd=0.2), runif(10, 0, 10)+rnorm(n,
    sd=0.2))
  par(bg="grey40")
  ds &lt;- dbscan(x, 0.2)
# run with showplot=1 to see how dbscan works.
  ds
  plot(ds, x)

  x2 &lt;- matrix(0,nrow=4,ncol=2)
  x2[1,] &lt;- c(5,2)
  x2[2,] &lt;- c(8,3)
  x2[3,] &lt;- c(4,4)
  x2[4,] &lt;- c(9,9)
  predict(ds, x, x2)

  n &lt;- 600
  x &lt;- cbind((1:3)+rnorm(n, sd=0.2), (1:3)+rnorm(n, sd=0.2))

# Not run, but results from my machine are 0.105 - 0.068 - 0.255:
#  system.time(ds &lt;- dbscan(x, 0.3, countmode=NULL, method="raw"))[3] 
#  system.time(dsb &lt;- dbscan(x, 0.3, countmode=NULL, method="hybrid"))[3]
#  system.time(dsc &lt;- dbscan(dist(x), 0.3, countmode=NULL,
#    method="dist"))[3]
</pre>

<hr /><div style="text-align: center;">[Package <em>fpc</em> version 2.1-11.1 <a href="00Index.html">Index</a>]</div>
</body></html>
