<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Dimension reduction for model-based clustering and...</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for MclustDR {mclust}"><tr><td>MclustDR {mclust}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Dimension reduction for model-based clustering and classification</h2>

<h3>Description</h3>

<p>A dimension reduction method for visualizing the clustering or classification structure obtained from a finite mixture of Gaussian densities.
</p>


<h3>Usage</h3>

<pre>
MclustDR(object, normalized = TRUE, Sigma, lambda = 0.5, 
         tol = sqrt(.Machine$double.eps))
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>object</code></td>
<td>
<p>An object of class <code>'Mclust'</code> or <code>'MclustDA'</code> resulting from a call to, respectively, <code><a href="Mclust.html">Mclust</a></code> or <code><a href="MclustDA.html">MclustDA</a></code>.
</p>
</td></tr>
<tr valign="top"><td><code>normalized</code></td>
<td>
<p>Logical. If <code>TRUE</code> directions are normalized to unit norm.
</p>
</td></tr>
<tr valign="top"><td><code>Sigma</code></td>
<td>
<p>Marginal covariance matrix of data. If not provided is estimated by the MLE of observed data.
</p>
</td></tr>
<tr valign="top"><td><code>lambda</code></td>
<td>
<p>A tuning parameter in the range [0,1] described in Scrucca (2014). 
The default 0.5 gives equal importance to differences in means and covariances 
among clusters/classes. To recover the directions that mostly separate the estimated
clusters or classes set this parameter to 1. 
</p>
</td></tr>
<tr valign="top"><td><code>tol</code></td>
<td>
<p>A tolerance value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method aims at reducing the dimensionality by identifying a set of linear combinations, ordered by importance as quantified by the associated eigenvalues, of the original features which capture most of the clustering or classification structure contained in the data. 
</p>
<p>Information on the dimension reduction subspace is obtained from the variation on group means and, depending on the estimated mixture model, on the variation on group covariances (see Scrucca, 2010). 
</p>
<p>Observations may then be projected onto such a reduced subspace, thus providing summary plots which help to visualize the underlying structure.
</p>
<p>The method has been extended to the supervised case, i.e. when the true classification is known (see Scrucca, 2013).
</p>
<p>This implementation doesn't provide a formal procedure for the selection of dimensionality. A future release will include one or more methods.
</p>


<h3>Value</h3>

<p>An object of class <code>'MclustDR'</code> with the following components:
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>call</code></td>
<td>
<p>The matched call</p>
</td></tr> 
<tr valign="top"><td><code>type</code></td>
<td>
<p>A character string specifying the type of model for which the dimension reduction is computed. Currently, possible values are <code>"Mclust"</code> for clustering, and <code>"MclustDA"</code> or <code>"EDDA"</code> for classification.</p>
</td></tr> 
<tr valign="top"><td><code>x</code></td>
<td>
<p>The data matrix.</p>
</td></tr>
<tr valign="top"><td><code>Sigma</code></td>
<td>
<p>The covariance matrix of the data.</p>
</td></tr>
<tr valign="top"><td><code>mixcomp</code></td>
<td>
<p>A numeric vector specifying the mixture component of each data observation.</p>
</td></tr>
<tr valign="top"><td><code>class</code></td>
<td>
<p>A factor specifying the classification of each data observation. For model-based clustering this is equivalent to the corresponding mixture component. For model-based classification this is the known classification.</p>
</td></tr>
<tr valign="top"><td><code>G</code></td>
<td>
<p>The number of mixture components.</p>
</td></tr>
<tr valign="top"><td><code>modelName</code></td>
<td>
<p>The name of the parameterization of the estimated mixture model(s). See <code><a href="mclustModelNames.html">mclustModelNames</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>mu</code></td>
<td>
<p>A matrix of means for each mixture component.</p>
</td></tr>
<tr valign="top"><td><code>sigma</code></td>
<td>
<p>An array of covariance matrices for each mixture component.</p>
</td></tr>
<tr valign="top"><td><code>pro</code></td>
<td>
<p>The estimated prior for each mixture component.</p>
</td></tr>
<tr valign="top"><td><code>M</code></td>
<td>
<p>The kernel matrix.</p>
</td></tr>
<tr valign="top"><td><code>lambda</code></td>
<td>
<p>The tuning parameter.</p>
</td></tr>
<tr valign="top"><td><code>evalues</code></td>
<td>
<p>The eigenvalues from the generalized eigen-decomposition of the kernel matrix.</p>
</td></tr>
<tr valign="top"><td><code>raw.evectors</code></td>
<td>
<p>The raw eigenvectors from the generalized eigen-decomposition of the kernel matrix, ordered according to the eigenvalues.</p>
</td></tr>
<tr valign="top"><td><code>basis</code></td>
<td>
<p>The basis of the estimated dimension reduction subspace.</p>
</td></tr>
<tr valign="top"><td><code>std.basis</code></td>
<td>
<p>The basis of the estimated dimension reduction subspace standardized to variables having unit standard deviation.</p>
</td></tr>
<tr valign="top"><td><code>numdir</code></td>
<td>
<p>The dimension of the projection subspace.</p>
</td></tr>
<tr valign="top"><td><code>dir</code></td>
<td>
<p>The estimated directions, i.e. the data projected onto the estimated dimension reduction subspace.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>References</h3>

<p>Scrucca, L. (2010) Dimension reduction for model-based clustering. <em>Statistics and Computing</em>, 20(4), pp. 471-484.
</p>
<p>Scrucca, L. (2014) Graphical Tools for Model-based Mixture Discriminant Analysis. <em>Advances in Data Analysis and Classification</em>, 8(2), pp. 147-165.
</p>


<h3>See Also</h3>

<p><code><a href="summary.MclustDR.html">summary.MclustDR</a></code>, <code><a href="plot.MclustDR.html">plot.MclustDR</a></code>, <code><a href="Mclust.html">Mclust</a></code>, <code><a href="MclustDA.html">MclustDA</a></code>.
</p>


<h3>Examples</h3>

<pre>
# clustering
data(diabetes)
mod &lt;- Mclust(diabetes[,-1])
summary(mod)

dr &lt;- MclustDR(mod)
summary(dr)
plot(dr, what = "scatterplot")
plot(dr, what = "evalues")

# adjust the tuning parameter to show the most separating directions
dr1 &lt;- MclustDR(mod, lambda = 1) 
summary(dr1)
plot(dr1, what = "scatterplot")
plot(dr1, what = "evalues")

# classification
data(banknote)

da &lt;- MclustDA(banknote[,2:7], banknote$Status, modelType = "EDDA")
dr &lt;- MclustDR(da)
summary(dr)

da &lt;- MclustDA(banknote[,2:7], banknote$Status)
dr &lt;- MclustDR(da)
summary(dr)
</pre>

<hr /><div style="text-align: center;">[Package <em>mclust</em> version 5.4.2 <a href="00Index.html">Index</a>]</div>
</body></html>
